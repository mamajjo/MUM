{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "!pip install scipy numpy matplotlib pandas sklearn tabulate seaborn jupyterthemes > /dev/null\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import read_json\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split, learning_curve, permutation_test_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, plot_roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import json\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import urllib.request \n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "# notebook styles\n",
    "# from jupyterthemes import jtplot\n",
    "# !jt -t onedork\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "# jtplot.style(theme='onedork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dataset configuration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, dataSourceUrl, dataResultUrl, test_size, n_splits, should_describe_data):\n",
    "        self.dataSourceUrl = dataSourceUrl\n",
    "        self.dataResultUrl = dataResultUrl\n",
    "        self.test_size = test_size\n",
    "        self.n_splits = n_splits\n",
    "        self.should_describe_data = should_describe_data\n",
    "\n",
    "def as_config(dict, dataSetName):\n",
    "    return Config(\n",
    "        dict[dataSetName]['dataSourceUrl'],\n",
    "        dict[dataSetName]['dataResultUrl'],\n",
    "        dict[dataSetName]['test_size'],\n",
    "        dict[dataSetName]['n_splits'],\n",
    "        dict[dataSetName]['should_describe_data'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "json_config = \"\"\"\n",
    "{\n",
    "    \"it_data\":{\n",
    "        \"dataSourceUrl\": \"./data/joinit_data.json\",\n",
    "        \"dataResultUrl\": \"./data/joinit_data.csv\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"n_splits\": 10,\n",
    "        \"should_describe_data\": true\n",
    "    }\n",
    "}\"\"\"\n",
    "curr_table = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Load (and describe) dataset, create test and train datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg = as_config(json.loads(json_config), 'it_data')\n",
    "\n",
    "df = read_json(cfg.dataSourceUrl)\n",
    "df.to_csv(cfg.dataResultUrl)\n",
    "df = df.drop(columns=[\"street\", \"address_text\", \"company_url\", \"latitude\", \"longitude\", \"company_logo_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save no-salary observations to separate dataframe: \"salaryless_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "salaryless_df = df.loc[((df.salary_currency.isnull()) | (df.salary_from.isnull()))]\n",
    "df = df.loc[((df.salary_currency.notnull()) & (df.salary_from.notnull()))]\n",
    "print(f\"Found {salaryless_df.shape[0]} job ads without salary range or currency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check numbers of unique country code, currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_exchange_rate(code, table):\n",
    "    return next(filter(lambda c: c[\"code\"]==code, curr_table[0][\"rates\"]))[\"mid\"]\n",
    "uniq_countries = df['country_code'].nunique()\n",
    "uniq_currencies = df['salary_currency'].nunique()\n",
    "if uniq_countries != 1 or uniq_currencies != 1:\n",
    "    print(f\"Found {uniq_countries} countries and {uniq_currencies} currencies!\")\n",
    "    print(f\"Dropping foreign countries and translating currencies...\")\n",
    "    df = df.loc[df[\"country_code\"] == \"PL\"]\n",
    "    if not curr_table:\n",
    "        with urllib.request.urlopen(\"https://api.nbp.pl/api/exchangerates/tables/a/?format=json\") as url:\n",
    "            curr_table = json.loads(url.read().decode())\n",
    "    to_translate = df.loc[df[\"salary_currency\"] != \"pln\"]\n",
    "    for curr in to_translate.salary_currency.unique():\n",
    "        ex_rate = find_exchange_rate(curr.upper(), curr_table)\n",
    "        df.loc[df[\"salary_currency\"] == curr] = df.loc[df[\"salary_currency\"] == curr].apply(lambda x: x*ex_rate if x.name in [\"salary_from\", \"salary_to\"] else (\"pln\" if x.name == \"salary_currency\" else x))\n",
    "    print(f\"Unique countries: {df['country_code'].nunique()}, currencies: {df['salary_currency'].nunique()}, observations: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.should_describe_data:    \n",
    "    print(df.shape)\n",
    "    display(HTML(tabulate(df.head(1), headers=df.columns, tablefmt=\"html\")))\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def setAxesRanges(axes):\n",
    "    for a in axes:\n",
    "        start, end = a.get_ylim()\n",
    "        a.yaxis.set_ticks(np.arange(start, end, (end-start)/4))\n",
    "        a.set_ylim(top=end*1.2)\n",
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "def transform_company_size(val):\n",
    "    val = val.replace('+', \"\").replace(\"<\", \"\").replace(\">\", \"\").replace(\" \", \"\")\n",
    "    if \"-\" in val:\n",
    "        ran = val.split(\"-\", 1)\n",
    "        if '' in ran:\n",
    "            return int(ran[0]) if ran[1] == \"\" else int(ran[1])\n",
    "        else:\n",
    "            return (int(ran[0])+int(ran[1]))/2\n",
    "    else:\n",
    "        return int(val)\n",
    "X = df[\"company_size\"].copy().values\n",
    "X = [transform_company_size(x) for x in X if hasNumbers(x)]\n",
    "first_X = [x for x in X if x < 1000]\n",
    "second_X = [x for x in X if x >= 1000 and x < 5000]\n",
    "third_X = [x for x in X if x >= 5000]\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "f, axes = plt.subplots(3, 1)\n",
    "sns.distplot(first_X, ax=axes[0], kde=False, hist=True);\n",
    "sns.distplot(second_X, ax=axes[1], kde=False, hist=True);\n",
    "sns.distplot(third_X, ax=axes[2], kde=False, hist=True);\n",
    "f.tight_layout()\n",
    "setAxesRanges(axes)\n",
    "sns.distplot(df.copy().assign(Spread=lambda df: 100*(df.salary_to-df.salary_from)/((df.salary_to+df.salary_from)/2)).Spread, kde=False, hist=True)\n",
    "with sns.axes_style(\"white\"):\n",
    "    without_outlier=df.copy()[df.salary_to<80_000]\n",
    "    sns.jointplot(x=without_outlier.salary_from, y=without_outlier.salary_to, kind=\"hex\");\n",
    "    sns.jointplot(x=without_outlier.salary_from, y=without_outlier.salary_to, data=df, kind=\"kde\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "# temp = dataset['skills'][0]\n",
    "skills_arr = []\n",
    "# skills = [skill_arr.append() for r in dataset['skills']]\n",
    "for r in dataset['skills']:\n",
    "    for name in r:\n",
    "        skills_arr.append(name['name'])\n",
    "unique_skills = np.unique(np.array(skills_arr))\n",
    "## usuwanie po znalezionych podobnych stwierdzeniach\n",
    "similar = []\n",
    "very_unique = []\n",
    "for skill in unique_skills:\n",
    "    if not skill in similar:\n",
    "        very_unique.append(skill)\n",
    "        similar += difflib.get_close_matches(skill, unique_skills, cutoff=0.1)\n",
    "\n",
    "## usuwanie po 1. słowie\n",
    "first_word = []\n",
    "very_very_unique = []\n",
    "for skill in very_unique:\n",
    "    if not skill.split(' ')[0] in first_word:\n",
    "        first_word.append(skill.split(' ')[0])\n",
    "        very_very_unique.append(skill)\n",
    "print(len(very_unique))\n",
    "pd.DataFrame(very_very_unique).to_csv('./data/skills_double_trim.csv')\n",
    "# dataset_skills = read_json(dataset['skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "x = array[:,0:len(dataset.columns)-1]\n",
    "y = array[:,len(dataset.columns)-1]\n",
    "#na podstawie x i y otrzymujemy tablice testowe i wynikowe\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x,y, test_size=cfg.test_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classification models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.extend([\n",
    "    ('KNN', KNeighborsClassifier(), 0),\n",
    "    ('CART', DecisionTreeClassifier(), 1),\n",
    "    ('NB', GaussianNB(), 2),\n",
    "    ('SVM', SVC(gamma='auto'), 3),\n",
    "    ('MLP', MLPClassifier(alpha=1e-5, hidden_layer_sizes=(50,10), max_iter=5000), 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classification</h2>\n",
    "kfold - k cross-validation to algorytm polegający na testowaniu nauczania(sprawdzania jego wydajności). \n",
    "Zbiór TESTOWY jest dzielony na K podzbiorów. W każdej z k iteracji,\n",
    "brane jest k-1 pozdbiorów, następuje ich nauczanie, następnie sprawdzenie 'jakości' nauczonego modelu.\n",
    "Przy pomocy danego algorytmu uczenia maszynowego!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_show():\n",
    "    pyplot.draw()\n",
    "    pyplot.pause(0.1)\n",
    "\n",
    "def get_specificity(y_validate, y_predicted):\n",
    "    cnf_matrix = confusion_matrix(y_validate, y_predicted)\n",
    "    \n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "    \n",
    "    FP = FP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "        \n",
    "    return np.mean(TN/(TN+FP))\n",
    "    \n",
    "def get_learning_curve(classification_model, training_set_enlarging_step=10):\n",
    "    train_sizes = np.linspace(0.1, 1, training_set_enlarging_step)\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        estimator = classification_model,\n",
    "        X = x,\n",
    "        y = y, \n",
    "        train_sizes = train_sizes,\n",
    "        cv = 5,\n",
    "        scoring = 'accuracy')\n",
    "    return train_sizes, train_scores, validation_scores\n",
    "\n",
    "def plot_learning_curve(model,name):\n",
    "    train_sizes, train_scores, test_scores = \\\n",
    "        get_learning_curve(model)\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "    plt.plot(train_sizes, -train_scores.mean(axis = 1), color= 'red', label = 'Training error')\n",
    "    plt.plot(train_sizes, -test_scores.mean(axis = 1), color= 'navy',label = 'Validation error')\n",
    "    plt.ylabel('Accuracy', fontsize = 14)\n",
    "    plt.xlabel('Training set size', fontsize = 14)\n",
    "    plt.title('Learning curves for a %s' % name, fontsize = 18, y = 1.03)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def compare_algorithms(results, names):\n",
    "    fig = pyplot.figure()\n",
    "    fig.suptitle(\"Algorithm Comparison\")\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_title(\"Algorithm Comparison\")\n",
    "    ax.boxplot(results, labels=names)\n",
    "    plot_show()\n",
    "\n",
    "def print_scores(cv_results, predictions):\n",
    "    print('\\nMean %f' % cv_results.mean())\n",
    "    print('STD %f' % cv_results.std())\n",
    "    print('\\nConfusion matrix:')\n",
    "    print(confusion_matrix(y_validation, predictions))\n",
    "    print('\\nAccuracy %f' % accuracy_score(y_validation, predictions))\n",
    "    print('Precision %f' % precision_score(y_validation, predictions, average = 'weighted'))\n",
    "    print('Recall %f' % recall_score(y_validation, predictions, average = 'weighted'))\n",
    "    print('Specificity %f' % get_specificity(y_validation, predictions))\n",
    "    print('\\nClassification report:')\n",
    "    print(classification_report(y_validation, predictions))\n",
    "\n",
    "def plot_roc_curves():\n",
    "    fig = pyplot.figure()\n",
    "    ax = plt.gca()\n",
    "    for name, model, subplot_row in models:\n",
    "        rfc_disp = plot_roc_curve(model, x_validation, \n",
    "                                  y_validation, ax=ax, alpha=0.8)\n",
    "    plt.show()\n",
    "\n",
    "def accuracySignificancy(model, x_train, y_train, cv):\n",
    "    fig = pyplot.figure()\n",
    "    fig.suptitle(\"Estimating accuracy score's statistical significancy\")\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    n_classes = np.unique(y_train).size\n",
    "    score, permutation_scores, pvalue = permutation_test_score(model, x_train, y_train, scoring=\"accuracy\", cv=cv, n_permutations=100)\n",
    "    print(\"Classification score %s (pvalue : %s)\" % (score, pvalue))\n",
    "    # View histogram of permutation scores\n",
    "    ax.hist(permutation_scores, 20, label='Permutation scores',\n",
    "             edgecolor='black')\n",
    "    ylim = plt.ylim()\n",
    "    ax.plot(2 * [score], ylim, '--g', linewidth=3,\n",
    "             label='Classification Score'\n",
    "             ' (pvalue %s)' % pvalue)\n",
    "    ax.plot(2 * [1. / n_classes], plt.ylim(), '--k', linewidth=3, label='Luck')\n",
    "    ax.set_xlabel('Score')\n",
    "    plt.show()\n",
    "\n",
    "def clustering_scores(x, labels_true=None):\n",
    "    inertias = []\n",
    "    silhouette_values = []\n",
    "    calinski_harabasz = []\n",
    "    davies_bouldin = []\n",
    "    k_range = 15\n",
    "    for k in range(2, k_range):\n",
    "        model = KMeans(n_clusters=k, random_state=1)\n",
    "        clustering = model.fit(x)\n",
    "        labels=clustering.labels_\n",
    "        inertias.append(clustering.inertia_)\n",
    "        silhouette_values.append(silhouette_score(x, labels))\n",
    "        calinski_harabasz.append(calinski_harabasz_score(x, labels))\n",
    "        davies_bouldin.append(davies_bouldin_score(x, labels))\n",
    "\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(8,32))\n",
    "    ax[0].plot(inertias)\n",
    "    ax[0].set_title(\"Elbow chart\")\n",
    "    ax[0].set_xlabel('clusters')\n",
    "    ax[0].set_ylabel('distortion')\n",
    "    ax[1].plot(silhouette_values)\n",
    "    ax[1].set_title(\"Silhouette score\")\n",
    "    ax[1].set_xlabel('clusters')\n",
    "    ax[1].set_ylabel('Silhouette score')\n",
    "    ax[2].plot(calinski_harabasz)\n",
    "    ax[2].set_title(\"Calinski Harabasz score\")\n",
    "    ax[2].set_xlabel('clusters')\n",
    "    ax[2].set_ylabel('Calinski Harabasz score')\n",
    "    ax[3].plot(davies_bouldin)\n",
    "    ax[3].set_title(\"Davies Bouldin score\")\n",
    "    ax[3].set_xlabel('clusters')\n",
    "    ax[3].set_ylabel('Davies Bouldin score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_per_dataset():\n",
    "    results = []\n",
    "    names = []\n",
    "    \n",
    "    for name, model, subplot_row in models:\n",
    "            print(f\"---------------------------\\nRunning classification for: {name}\")\n",
    "            kfold = StratifiedKFold(n_splits=cfg.n_splits, random_state=1, shuffle=True)\n",
    "            cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='accuracy')\n",
    "            accuracySignificancy(model, x_train, y_train, kfold)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "\n",
    "            # Make predictions on validation dataset\n",
    "            model.fit(x_train, y_train)\n",
    "            predictions = model.predict(x_validation)\n",
    "            \n",
    "            print_scores(cv_results, predictions)\n",
    "            plot_learning_curve(model,name)\n",
    "    #ROC\n",
    "    plot_roc_curves()\n",
    "\n",
    "    # Compare Algorithms - ROC etc\n",
    "    compare_algorithms(results, names)\n",
    "    \n",
    "    clustering_scores(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate_per_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
