{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "!pip install scipy numpy matplotlib pandas sklearn > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import read_json\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split, learning_curve, permutation_test_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, plot_roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dataset configuration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, dataSourceUrl, dataResultUrl, test_size, n_splits, should_describe_data):\n",
    "        self.dataSourceUrl = dataSourceUrl\n",
    "        self.dataResultUrl = dataResultUrl\n",
    "        self.test_size = test_size\n",
    "        self.n_splits = n_splits\n",
    "        self.should_describe_data = should_describe_data\n",
    "\n",
    "def as_config(dict, dataSetName):\n",
    "    return Config(\n",
    "        dict[dataSetName]['dataSourceUrl'],\n",
    "        dict[dataSetName]['dataResultUrl'],\n",
    "        dict[dataSetName]['test_size'],\n",
    "        dict[dataSetName]['n_splits'],\n",
    "        dict[dataSetName]['should_describe_data'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "json_config = \"\"\"\n",
    "{\n",
    "    \"it_data\":{\n",
    "        \"dataSourceUrl\": \"./data/joinit_data.json\",\n",
    "        \"dataResultUrl\": \"./data/joinit_data.csv\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"n_splits\": 10,\n",
    "        \"should_describe_data\": true\n",
    "    }\n",
    "}\"\"\"\n",
    "cfg = json.loads(json_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Load (and describe) dataset, create test and train datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cfg = as_config(cfg, 'it_data')\n",
    "\n",
    "dataset = read_json(cfg.dataSourceUrl)\n",
    "# dataset.to_csv(cfg.dataResultUrl)\n",
    "if cfg.should_describe_data:    \n",
    "    print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading generalized skill labels and adding it as columns to dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(dataset)\n",
    "skill_map = read_csv('./data/skills_mapped.csv', sep=\":\")\n",
    "unique_skill_columns = (skill_map['mapping'].unique())\n",
    "\n",
    "for skill in unique_skill_columns:\n",
    "    dataset[str(skill)] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each row, map skill/level to generalized column label\n",
    "Result in result_df, saved to file.\n",
    "\n",
    "##### note that it only works on preformated skills_mapped csv."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df = dataset\n",
    "for index, row in dataset.iterrows():\n",
    "    skill_dict = row['skills']\n",
    "    for skill_level_tuple in skill_dict:\n",
    "        name = skill_level_tuple['name']\n",
    "        name_index_in_map = np.where(skill_map['Skill'] == name)[0][0]\n",
    "        name = skill_map.iloc[name_index_in_map]['mapping']\n",
    "        if not name == '-':\n",
    "            if row[name] == 0:\n",
    "                row[name] = skill_level_tuple['level']\n",
    "            elif not row[name] == 0:\n",
    "                row[name] = row[name] if row[name] >= skill_level_tuple['level'] else skill_level_tuple['level']\n",
    "    result_df.loc[index] = row\n",
    "result_df.to_csv(\"./data/result_table.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Old stuff after that cell"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "# temp = dataset['skills'][0]\n",
    "skills_arr = []\n",
    "# skills = [skill_arr.append() for r in dataset['skills']]\n",
    "for r in dataset['skills']:\n",
    "    for name in r:\n",
    "        skills_arr.append(name['name'])\n",
    "unique_skills = np.unique(np.array(skills_arr))\n",
    "## usuwanie po znalezionych podobnych stwierdzeniach\n",
    "similar = []\n",
    "very_unique = []\n",
    "for skill in unique_skills:\n",
    "    if not skill in similar:\n",
    "        very_unique.append(skill)\n",
    "        similar += difflib.get_close_matches(skill, unique_skills, cutoff=0.1)\n",
    "\n",
    "## usuwanie po 1. słowie\n",
    "first_word = []\n",
    "very_very_unique = []\n",
    "for skill in very_unique:\n",
    "    if not skill.split(' ')[0] in first_word:\n",
    "        first_word.append(skill.split(' ')[0])\n",
    "        very_very_unique.append(skill)\n",
    "print(len(very_unique))\n",
    "pd.DataFrame(very_very_unique).to_csv('./data/skills_double_trim.csv')\n",
    "# dataset_skills = read_json(dataset['skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "x = array[:,0:len(dataset.columns)-1]\n",
    "y = array[:,len(dataset.columns)-1]\n",
    "#na podstawie x i y otrzymujemy tablice testowe i wynikowe\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x,y, test_size=cfg.test_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classification models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.extend([\n",
    "    ('KNN', KNeighborsClassifier(), 0),\n",
    "    ('CART', DecisionTreeClassifier(), 1),\n",
    "    ('NB', GaussianNB(), 2),\n",
    "    ('SVM', SVC(gamma='auto'), 3),\n",
    "    ('MLP', MLPClassifier(alpha=1e-5, hidden_layer_sizes=(50,10), max_iter=5000), 4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classification</h2>\n",
    "kfold - k cross-validation to algorytm polegający na testowaniu nauczania(sprawdzania jego wydajności). \n",
    "Zbiór TESTOWY jest dzielony na K podzbiorów. W każdej z k iteracji,\n",
    "brane jest k-1 pozdbiorów, następuje ich nauczanie, następnie sprawdzenie 'jakości' nauczonego modelu.\n",
    "Przy pomocy danego algorytmu uczenia maszynowego!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_show():\n",
    "    pyplot.draw()\n",
    "    pyplot.pause(0.1)\n",
    "\n",
    "def get_specificity(y_validate, y_predicted):\n",
    "    cnf_matrix = confusion_matrix(y_validate, y_predicted)\n",
    "    \n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "    \n",
    "    FP = FP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "        \n",
    "    return np.mean(TN/(TN+FP))\n",
    "    \n",
    "def get_learning_curve(classification_model, training_set_enlarging_step=10):\n",
    "    train_sizes = np.linspace(0.1, 1, training_set_enlarging_step)\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        estimator = classification_model,\n",
    "        X = x,\n",
    "        y = y, \n",
    "        train_sizes = train_sizes,\n",
    "        cv = 5,\n",
    "        scoring = 'accuracy')\n",
    "    return train_sizes, train_scores, validation_scores\n",
    "\n",
    "def plot_learning_curve(model,name):\n",
    "    train_sizes, train_scores, test_scores = \\\n",
    "        get_learning_curve(model)\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "    plt.plot(train_sizes, -train_scores.mean(axis = 1), color= 'red', label = 'Training error')\n",
    "    plt.plot(train_sizes, -test_scores.mean(axis = 1), color= 'navy',label = 'Validation error')\n",
    "    plt.ylabel('Accuracy', fontsize = 14)\n",
    "    plt.xlabel('Training set size', fontsize = 14)\n",
    "    plt.title('Learning curves for a %s' % name, fontsize = 18, y = 1.03)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def compare_algorithms(results, names):\n",
    "    fig = pyplot.figure()\n",
    "    fig.suptitle(\"Algorithm Comparison\")\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_title(\"Algorithm Comparison\")\n",
    "    ax.boxplot(results, labels=names)\n",
    "    plot_show()\n",
    "\n",
    "def print_scores(cv_results, predictions):\n",
    "    print('\\nMean %f' % cv_results.mean())\n",
    "    print('STD %f' % cv_results.std())\n",
    "    print('\\nConfusion matrix:')\n",
    "    print(confusion_matrix(y_validation, predictions))\n",
    "    print('\\nAccuracy %f' % accuracy_score(y_validation, predictions))\n",
    "    print('Precision %f' % precision_score(y_validation, predictions, average = 'weighted'))\n",
    "    print('Recall %f' % recall_score(y_validation, predictions, average = 'weighted'))\n",
    "    print('Specificity %f' % get_specificity(y_validation, predictions))\n",
    "    print('\\nClassification report:')\n",
    "    print(classification_report(y_validation, predictions))\n",
    "\n",
    "def plot_roc_curves():\n",
    "    fig = pyplot.figure()\n",
    "    ax = plt.gca()\n",
    "    for name, model, subplot_row in models:\n",
    "        rfc_disp = plot_roc_curve(model, x_validation, \n",
    "                                  y_validation, ax=ax, alpha=0.8)\n",
    "    plt.show()\n",
    "\n",
    "def accuracySignificancy(model, x_train, y_train, cv):\n",
    "    fig = pyplot.figure()\n",
    "    fig.suptitle(\"Estimating accuracy score's statistical significancy\")\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    n_classes = np.unique(y_train).size\n",
    "    score, permutation_scores, pvalue = permutation_test_score(model, x_train, y_train, scoring=\"accuracy\", cv=cv, n_permutations=100)\n",
    "    print(\"Classification score %s (pvalue : %s)\" % (score, pvalue))\n",
    "    # View histogram of permutation scores\n",
    "    ax.hist(permutation_scores, 20, label='Permutation scores',\n",
    "             edgecolor='black')\n",
    "    ylim = plt.ylim()\n",
    "    ax.plot(2 * [score], ylim, '--g', linewidth=3,\n",
    "             label='Classification Score'\n",
    "             ' (pvalue %s)' % pvalue)\n",
    "    ax.plot(2 * [1. / n_classes], plt.ylim(), '--k', linewidth=3, label='Luck')\n",
    "    ax.set_xlabel('Score')\n",
    "    plt.show()\n",
    "\n",
    "def clustering_scores(x, labels_true=None):\n",
    "    inertias = []\n",
    "    silhouette_values = []\n",
    "    calinski_harabasz = []\n",
    "    davies_bouldin = []\n",
    "    k_range = 15\n",
    "    for k in range(2, k_range):\n",
    "        model = KMeans(n_clusters=k, random_state=1)\n",
    "        clustering = model.fit(x)\n",
    "        labels=clustering.labels_\n",
    "        inertias.append(clustering.inertia_)\n",
    "        silhouette_values.append(silhouette_score(x, labels))\n",
    "        calinski_harabasz.append(calinski_harabasz_score(x, labels))\n",
    "        davies_bouldin.append(davies_bouldin_score(x, labels))\n",
    "\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(8,32))\n",
    "    ax[0].plot(inertias)\n",
    "    ax[0].set_title(\"Elbow chart\")\n",
    "    ax[0].set_xlabel('clusters')\n",
    "    ax[0].set_ylabel('distortion')\n",
    "    ax[1].plot(silhouette_values)\n",
    "    ax[1].set_title(\"Silhouette score\")\n",
    "    ax[1].set_xlabel('clusters')\n",
    "    ax[1].set_ylabel('Silhouette score')\n",
    "    ax[2].plot(calinski_harabasz)\n",
    "    ax[2].set_title(\"Calinski Harabasz score\")\n",
    "    ax[2].set_xlabel('clusters')\n",
    "    ax[2].set_ylabel('Calinski Harabasz score')\n",
    "    ax[3].plot(davies_bouldin)\n",
    "    ax[3].set_title(\"Davies Bouldin score\")\n",
    "    ax[3].set_xlabel('clusters')\n",
    "    ax[3].set_ylabel('Davies Bouldin score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def count_percentage():\n",
    "    experience_level_count = dataset['experience_level'].value_counts()\n",
    "    experience_level_percentage = dataset['experience_level'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "    \n",
    "    \n",
    "    marker_icon_count = dataset['marker_icon'].value_counts()\n",
    "    marker_icon_percentage = dataset['marker_icon'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "    \n",
    "    \n",
    "    employment_type_count = dataset['employment_type'].value_counts()\n",
    "    employment_type_percentage = dataset['employment_type'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "    \n",
    "    df1 = pd.DataFrame({'Count': marker_icon_count, 'Percentage': marker_icon_percentage})\n",
    "    df2 = pd.DataFrame({'Count': experience_level_count, 'Percentage': experience_level_percentage})\n",
    "    df3 = pd.DataFrame({'Count': employment_type_count, 'Percentage': employment_type_percentage})\n",
    "    display(df1)\n",
    "    display(df2)\n",
    "    display(df3)\n",
    "\n",
    "def evaluate_per_dataset():\n",
    "    results = []\n",
    "    names = []\n",
    "    \n",
    "    for name, model, subplot_row in models:\n",
    "            print(f\"---------------------------\\nRunning classification for: {name}\")\n",
    "            kfold = StratifiedKFold(n_splits=cfg.n_splits, random_state=1, shuffle=True)\n",
    "            cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='accuracy')\n",
    "            accuracySignificancy(model, x_train, y_train, kfold)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "\n",
    "            # Make predictions on validation dataset\n",
    "            model.fit(x_train, y_train)\n",
    "            predictions = model.predict(x_validation)\n",
    "            \n",
    "            print_scores(cv_results, predictions)\n",
    "            plot_learning_curve(model,name)\n",
    "    #ROC\n",
    "    plot_roc_curves()\n",
    "\n",
    "    # Compare Algorithms - ROC etc\n",
    "    compare_algorithms(results, names)\n",
    "    \n",
    "    clustering_scores(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate_per_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38164bitvenvvenv4b743eb649db48ea85d2321157db5c5a",
   "language": "python",
   "display_name": "Python 3.8.1 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}