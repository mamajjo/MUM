{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "!pip install scipy numpy matplotlib pandas sklearn tabulate seaborn folium geopy geopandas requests> /dev/null\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from geopy import Nominatim\n",
    "from pandas import read_csv, read_json\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split, learning_curve, permutation_test_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, plot_roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import json\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import urllib.request \n",
    "from tabulate import tabulate\n",
    "import requests\n",
    "import webbrowser\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import geopandas as gpd\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, dataSourceRaw, dataSourceMapped, useOnlineData, test_size, n_splits, should_describe_data):\n",
    "        self.dataSourceRaw = dataSourceRaw\n",
    "        self.dataSourceMapped = dataSourceMapped\n",
    "        self.useOnlineData = useOnlineData\n",
    "        self.test_size = test_size\n",
    "        self.n_splits = n_splits\n",
    "        self.should_describe_data = should_describe_data\n",
    "\n",
    "def as_config(dict, dataSetName):\n",
    "    return Config(\n",
    "        dict[dataSetName]['dataSourceRaw'],\n",
    "        dict[dataSetName]['dataSourceMapped'],\n",
    "        dict[dataSetName]['useOnlineData'],\n",
    "        dict[dataSetName]['test_size'],\n",
    "        dict[dataSetName]['n_splits'],\n",
    "        dict[dataSetName]['should_describe_data'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "json_config = \"\"\"\n",
    "{\n",
    "    \"it_data\":{\n",
    "        \"dataSourceRaw\": \"./data/result_table.csv\",\n",
    "        \"dataSourceMapped\": \"./data/joinit_data.csv\",\n",
    "        \"useOnlineData\": false,\n",
    "        \"test_size\": 0.2,\n",
    "        \"n_splits\": 10,\n",
    "        \"should_describe_data\": true\n",
    "    }\n",
    "}\"\"\"\n",
    "cfg = as_config(json.loads(json_config), 'it_data')\n",
    "curr_table = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs_info(api_url = 'https://justjoin.it/api/offers'):\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    print(f\"Response status: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content.decode('utf-8'))\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and map skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_columns_to_csv(dataset):\n",
    "    skill_map = read_csv('./data/skills_mapped.csv', sep=\":\")\n",
    "    unique_skill_columns = (skill_map['mapping'].unique())\n",
    "\n",
    "    for skill in unique_skill_columns:\n",
    "        dataset[str(skill)] = 0\n",
    "    result_df = dataset\n",
    "    for index, row in dataset.iterrows():\n",
    "        skill_dict = row['skills']\n",
    "        for skill_level_tuple in skill_dict:\n",
    "            name = skill_level_tuple['name']\n",
    "            mapped_val = np.where(skill_map['Skill'] == name)\n",
    "            if len(mapped_val) is 0 or len(mapped_val[0]) is 0:\n",
    "                # TEMPORARY HACK\n",
    "                print(f\"Could not find '{name}' in map\")\n",
    "                continue\n",
    "            name_index_in_map = mapped_val[0][0]\n",
    "            name = skill_map.iloc[name_index_in_map]['mapping']\n",
    "            if not name == '-':\n",
    "                if row[name] == 0:\n",
    "                    row[name] = skill_level_tuple['level']\n",
    "                elif not row[name] == 0:\n",
    "                    row[name] = row[name] if row[name] >= skill_level_tuple['level'] else skill_level_tuple['level']\n",
    "        result_df.loc[index] = row\n",
    "    result_df.to_csv(cfg.dataSourceMapped)\n",
    "\n",
    "def find_exchange_rate(code, table):\n",
    "    return next(filter(lambda c: c[\"code\"]==code, table[0][\"rates\"]))[\"mid\"]\n",
    "def take_only_country_translate_currency(df):\n",
    "    curr_table = None\n",
    "    uniq_countries = df['country_code'].nunique()\n",
    "    uniq_currencies = df['salary_currency'].nunique()\n",
    "    if uniq_countries != 1 or uniq_currencies != 1:\n",
    "        print(f\"Found {uniq_countries} countries and {uniq_currencies} currencies!\")\n",
    "        print(f\"Dropping foreign countries and translating currencies...\")\n",
    "        df = df.loc[df[\"country_code\"] == \"PL\"]\n",
    "        if not curr_table:\n",
    "            with urllib.request.urlopen(\"https://api.nbp.pl/api/exchangerates/tables/a/?format=json\") as url:\n",
    "                curr_table = json.loads(url.read().decode())\n",
    "        to_translate = df.loc[df[\"salary_currency\"] != \"pln\"]\n",
    "        for curr in to_translate.salary_currency.unique():\n",
    "            ex_rate = find_exchange_rate(curr.upper(), curr_table)\n",
    "            df.loc[df[\"salary_currency\"] == curr] = df.loc[df[\"salary_currency\"] == curr].apply(lambda x: x*ex_rate if x.name in [\"salary_from\", \"salary_to\"] else (\"pln\" if x.name == \"salary_currency\" else x))\n",
    "        print(f\"Unique countries: {df['country_code'].nunique()}, currencies: {df['salary_currency'].nunique()}, observations: {df.shape[0]}\")\n",
    "    return df\n",
    "    \n",
    "def read_dataset():\n",
    "    if cfg.useOnlineData:\n",
    "        print(\"Taking data from online source...\")\n",
    "        jjit_json = get_jobs_info()\n",
    "        dataset = json_normalize(jjit_json)\n",
    "        map_columns_to_csv(dataset)\n",
    "        return read_csv(cfg.dataSourceMapped)\n",
    "    else:\n",
    "        print(\"Taking data from local file...\")\n",
    "        return read_csv(cfg.dataSourceRaw)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.drop(columns=[\"street\", \"address_text\", \"company_url\", \"company_logo_url\"])\n",
    "    # Save no-salary observations to separate dataframe: \"salaryless_df\"\n",
    "    global salaryless_df\n",
    "    salaryless_df = df.loc[((df.salary_currency.isnull()) | (df.salary_from.isnull()))]\n",
    "    df = df.loc[((df.salary_currency.notnull()) & (df.salary_from.notnull()))]\n",
    "    print(f\"Found {salaryless_df.shape[0]} job ads without salary range or currency\")\n",
    "    if cfg.should_describe_data:    \n",
    "        print(df.shape)\n",
    "        print(df[[\"salary_from\", \"salary_to\"]].describe())\n",
    "    df = take_only_country_translate_currency(df)\n",
    "    return df\n",
    "    \n",
    "def get_dataset():\n",
    "    return preprocess_data(read_dataset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot company sizes and salary ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setAxesRanges(axes):\n",
    "    for a in axes:\n",
    "        start, end = a.get_ylim()\n",
    "        a.yaxis.set_ticks(np.arange(start, end, (end-start)/4))\n",
    "        a.set_ylim(top=end*1.2)\n",
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "def transform_company_size(val):\n",
    "    val = val.replace('+', \"\").replace(\"<\", \"\").replace(\">\", \"\").replace(\" \", \"\")\n",
    "    if \"-\" in val:\n",
    "        ran = val.split(\"-\", 1)\n",
    "        if '' in ran:\n",
    "            return int(ran[0]) if ran[1] == \"\" else int(ran[1])\n",
    "        else:\n",
    "            return (int(ran[0])+int(ran[1]))/2\n",
    "    else:\n",
    "        return int(val)\n",
    "X = df[\"company_size\"].copy().values\n",
    "X = [transform_company_size(x) for x in X if hasNumbers(x)]\n",
    "first_X = [x for x in X if x < 1000]\n",
    "second_X = [x for x in X if x >= 1000 and x < 5000]\n",
    "third_X = [x for x in X if x >= 5000]\n",
    "\n",
    "salary_threshold = 80_000\n",
    "too_high_to_plot_count = df[df.salary_to>=salary_threshold].size\n",
    "if too_high_to_plot_count > 0:\n",
    "    print(f\"Found {too_high_to_plot_count} jobs with salary over {salary_threshold}, which won't be taken into account on plots below.\")\n",
    "sns.set(color_codes=True)\n",
    "f, axes = plt.subplots(3, 1)\n",
    "sns.distplot(first_X, ax=axes[0], kde=False, hist=True);\n",
    "sns.distplot(second_X, ax=axes[1], kde=False, hist=True);\n",
    "sns.distplot(third_X, ax=axes[2], kde=False, hist=True);\n",
    "f.tight_layout()\n",
    "setAxesRanges(axes)\n",
    "sns.distplot(df.copy().assign(Spread=lambda df: 100*(df.salary_to-df.salary_from)/((df.salary_to+df.salary_from)/2)).Spread, kde=False, hist=True)\n",
    "with sns.axes_style(\"white\"):\n",
    "    without_outlier=df.copy()[df.salary_to<salary_threshold]\n",
    "    sns.jointplot(x=without_outlier.salary_from, y=without_outlier.salary_to, kind=\"hex\");\n",
    "    sns.jointplot(x=without_outlier.salary_from, y=without_outlier.salary_to, data=df, kind=\"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_percentage():\n",
    "    experience_level_count = df['experience_level'].value_counts()\n",
    "    experience_level_percentage = df['experience_level'].value_counts(normalize=True)\n",
    "    \n",
    "    \n",
    "    marker_icon_count = df['marker_icon'].value_counts()\n",
    "    marker_icon_percentage = df['marker_icon'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "    \n",
    "    \n",
    "    employment_type_count = df['employment_type'].value_counts()\n",
    "    employment_type_percentage = df['employment_type'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "    \n",
    "    df1 = pd.DataFrame({'Count': marker_icon_count, 'Percentage': marker_icon_percentage})\n",
    "    df2 = pd.DataFrame({'Count': experience_level_count, 'Percentage': experience_level_percentage.mul(100).round(1).astype(str) + '%'})\n",
    "    df3 = pd.DataFrame({'Count': employment_type_count, 'Percentage': employment_type_percentage})\n",
    "    display(df1)\n",
    "    df1.copy()[df1.Count>=25].plot.pie(y='Count', legend=False, figsize=(10, 10), autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    display(df2)\n",
    "    df2.plot.pie(y='Count', figsize=(5, 5), legend=False, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    display(df3)\n",
    "    df3.plot.pie(y='Count', figsize=(5, 5), legend=False, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "count_percentage()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_column_name = 'lat'\n",
    "lon_column_name = 'lon'\n",
    "numerical_column_name = 'no'\n",
    "province_column_name = 'province'\n",
    "province_id_column_name = 'province_id'\n",
    "city_column_name = 'city'\n",
    "id_column_name = 'id'\n",
    "country_code_column_name = 'country_code'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Coordinates load</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_province_from_address (address_text, province_string = \"województwo \",\n",
    "                               split_sign=\",\"):\n",
    "    province = address_text.partition(province_string)[2] \n",
    "    province = province.partition(split_sign)[0] \n",
    "    \n",
    "    return province\n",
    "    \n",
    "def fill_geo_info(places_data, loc_column_name, fill_province = False):\n",
    "    locator = Nominatim(user_agent=\"myGeocoder\")\n",
    "    \n",
    "    for i, row in places_data.iterrows():\n",
    "        location = locator.geocode(row[loc_column_name])\n",
    "        if location is not None:\n",
    "            places_data.loc[i,lat_column_name] = location.latitude\n",
    "            places_data.loc[i,lon_column_name] = location.longitude\n",
    "            if fill_province:\n",
    "                places_data.loc[i, province_column_name] = get_province_from_address(\n",
    "                location.address)\n",
    "        else:\n",
    "            print(f\"Could not find latitude/longitude for {row[loc_column_name]}\")\n",
    "            \n",
    "    return places_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Print heat map methods</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_heat_map(places_data, file_path = 'heat_map.html', \n",
    "                   heat_column_name = numerical_column_name):\n",
    "\n",
    "    places_len = len(places_data)\n",
    "    \n",
    "    lat = np.array(places_data[lat_column_name][0:places_len])\n",
    "    lon = np.array(places_data[lon_column_name][0:places_len])\n",
    "    no = np.array(places_data[heat_column_name][0:places_len],dtype=float)\n",
    "    data = [[lat[i],lon[i],no[i]] for i in range(places_len)] \n",
    "    \n",
    "    #location is the center location, draw a Map, and start zooming is 6 times.\n",
    "    map_osm = folium.Map(location=[lat.mean(),lon.mean()],zoom_start=6,control_scale=True)\n",
    "    HeatMap(data).add_to(map_osm) # Add heat map to the created map\n",
    "    display(map_osm)\n",
    "    map_osm.save(file_path) # Save as html file\n",
    "    webbrowser.open(file_path) # Default browser open\n",
    "\n",
    "def print_province_heat_map(province_data = None, heat_column_name = numerical_column_name,\n",
    "                            province_key_column_name = province_id_column_name,\n",
    "                            file_path = 'province_heat_map.html',\n",
    "                            legend_name = None):    \n",
    "    #preprocessing \n",
    "    province_data = province_data.dropna()\n",
    "    province_data[province_id_column_name]=\\\n",
    "        province_data[province_id_column_name].astype(int)\n",
    "    \n",
    "    province_geo_paths = get_province_geo_paths()\n",
    "    province_map = folium.Map([52, 19], zoom_start=6)\n",
    "    folium.Choropleth(geo_data=province_geo_paths,\n",
    "                  data=province_data,\n",
    "                    # kolumna z kluczem, kolumna z wartościami\n",
    "                  columns=[province_key_column_name, heat_column_name], \n",
    "                      # klucz z geoJSON\n",
    "                  key_on='feature.properties.JPT_KOD_JE', \n",
    "                  fill_color='YlOrRd', \n",
    "                  fill_opacity=0.7,\n",
    "                  line_opacity=0.2,\n",
    "                  legend_name=legend_name).add_to(province_map)\n",
    "    # zapisanie utworzonej mapy do pliku HTML\n",
    "    display(province_map)\n",
    "    province_map.save(outfile = file_path)\n",
    "    webbrowser.open(file_path) # Default browser open\n",
    "    \n",
    "def get_province_geo_paths():\n",
    "    province_shapes = gpd.read_file('wojewodztwa.shp')\n",
    "    province_shapes = province_shapes[['JPT_KOD_JE', \"geometry\"]]\n",
    "    province_shapes['JPT_KOD_JE']=province_shapes['JPT_KOD_JE'].astype(int)\n",
    "    \n",
    "    # uproszczenie geometrii (mniejsza wartosc = bardziej dokładnie)\n",
    "    province_shapes.geometry = province_shapes.geometry.simplify(0.005)\n",
    "    province_geo_path = province_shapes.to_json()\n",
    "    return province_geo_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_city(data, address_column_name):\n",
    "    unique_places = data.groupby(address_column_name)[id_column_name].nunique()\n",
    "    places = pd.DataFrame({city_column_name:unique_places.index,\n",
    "                           numerical_column_name:unique_places.values})\n",
    "    places[lat_column_name]=np.nan\n",
    "    places[lon_column_name]=np.nan\n",
    "    return places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print heat map with offer count\n",
    "grouped_city_data = group_by_city(df, city_column_name)\n",
    "places_map = fill_geo_info(grouped_city_data, city_column_name)\n",
    "print_heat_map(places_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get province data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_province_ids():\n",
    "    return pd.read_csv('woj_oznaczenia.csv', engine='python')\n",
    "\n",
    "\n",
    "def get_city_data(data, address_column_name):\n",
    "    unique_places = data.groupby(address_column_name)[id_column_name].nunique()\n",
    "    \n",
    "    places = pd.DataFrame({city_column_name:unique_places.index})\n",
    "    places[lat_column_name]=np.nan\n",
    "    places[lon_column_name]=np.nan\n",
    "    places[province_column_name]=np.nan\n",
    "    \n",
    "    return places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_map = get_city_data(df, city_column_name)\n",
    "places_map = fill_geo_info(places_map, city_column_name, fill_province=True)\n",
    "\n",
    "# jjit_data = jjit_data.drop([lat_column_name, lon_column_name, province_column_name])\n",
    "jjit_data = pd.merge(df, places_map, how='outer', \n",
    "                     left_on=city_column_name, right_on=city_column_name)\n",
    "\n",
    "province_ids = get_province_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Print heat map for min/max average salary </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#group by province and aggregate min salary\n",
    "min_salary_per_province_data = jjit_data.groupby(by=province_column_name) \\\n",
    "       .agg({'salary_from':'mean'}) \\\n",
    "       .rename(columns={'salary_from':'mean_salary_from'}) \\\n",
    "       .reset_index()\n",
    "\n",
    "#merge with province GUGiK data (we need province id)\n",
    "province_data = pd.merge(min_salary_per_province_data, province_ids, how='outer',\n",
    "                         left_on=province_column_name, right_on=province_column_name)\n",
    "\n",
    "print_province_heat_map(province_data = province_data,\n",
    "                        heat_column_name=\"mean_salary_from\",\n",
    "                        file_path=\"min.html\",\n",
    "                        legend_name=\"Średnie minimalne wynagrodzenia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#group by province and aggregate max salary\n",
    "max_salary_per_province_data = jjit_data.groupby(province_column_name) \\\n",
    "       .agg({'salary_to':'mean'}) \\\n",
    "       .rename(columns={'salary_to':'mean_salary_to'}) \\\n",
    "       .reset_index()\n",
    "\n",
    "#merge with province GUGiK data (we need province id)\n",
    "province_data = pd.merge(max_salary_per_province_data, province_ids, how='outer',\n",
    "                         left_on=province_column_name, right_on=province_column_name)\n",
    "\n",
    "print_province_heat_map(province_data = province_data,\n",
    "                        heat_column_name=\"mean_salary_to\",\n",
    "                        file_path=\"maks.html\",\n",
    "                        legend_name=\"Średnie maksymalne wynagrodzenia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_df = df.copy()\n",
    "for col in [\"city\", \"Unnamed: 0\", \"title\", \"company_size\", \"country_code\", \"marker_icon\", \"company_name\",\n",
    "            \"latitude\", \"longitude\", \"salary_currency\", \"published_at\", \"remote_interview\", \"id\",\n",
    "            \"Vert.x\", \"skills\", \"-\"]:\n",
    "                cl_df=cl_df.drop(col, axis=1)\n",
    "print(cl_df.columns)\n",
    "cols_for_encoding = [c for c in cl_df.select_dtypes(include=['object']).copy().columns if c != \"experience_level\"]\n",
    "print(cols_for_encoding)\n",
    "cl_df = pd.get_dummies(cl_df, columns=cols_for_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cl_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_col_to_end(df, col):\n",
    "    cols_at_end = [col]\n",
    "    return df[[c for c in df if c not in cols_at_end] \n",
    "            + [c for c in cols_at_end if c in df]]\n",
    "\n",
    "cl_df = move_col_to_end(cl_df, \"experience_level\")\n",
    "array = cl_df.values\n",
    "x = array[:,0:len(cl_df.columns)-1]\n",
    "y = array[:,len(cl_df.columns)-1]\n",
    "x = normalize(x)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "#na podstawie x i y otrzymujemy tablice testowe i wynikowe\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x,y, test_size=cfg.test_size, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.extend([\n",
    "    ('KNN', KNeighborsClassifier(), 0),\n",
    "    ('CART', DecisionTreeClassifier(), 1),\n",
    "    ('NB', GaussianNB(), 2),\n",
    "    ('SVM', SVC(gamma='auto'), 3),\n",
    "    ('MLP', MLPClassifier(alpha=1e-5, hidden_layer_sizes=(50,10), max_iter=5000), 4)\n",
    "    ])\n",
    "def plot_show():\n",
    "    pyplot.draw()\n",
    "    pyplot.pause(0.1)\n",
    "\n",
    "def get_specificity(y_validate, y_predicted):\n",
    "    cnf_matrix = confusion_matrix(y_validate, y_predicted)\n",
    "    \n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "    \n",
    "    FP = FP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "        \n",
    "    return np.mean(TN/(TN+FP))\n",
    "    \n",
    "def get_learning_curve(classification_model, training_set_enlarging_step=10):\n",
    "    train_sizes = np.linspace(0.1, 1, training_set_enlarging_step)\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        estimator = classification_model,\n",
    "        X = x,\n",
    "        y = y, \n",
    "        train_sizes = train_sizes,\n",
    "        cv = 5,\n",
    "        scoring = 'accuracy')\n",
    "    return train_sizes, train_scores, validation_scores\n",
    "\n",
    "def plot_learning_curve(model,name):\n",
    "    train_sizes, train_scores, test_scores = \\\n",
    "        get_learning_curve(model)\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "    plt.plot(train_sizes, -train_scores.mean(axis = 1), color= 'red', label = 'Training error')\n",
    "    plt.plot(train_sizes, -test_scores.mean(axis = 1), color= 'navy',label = 'Validation error')\n",
    "    plt.ylabel('Accuracy', fontsize = 14)\n",
    "    plt.xlabel('Training set size', fontsize = 14)\n",
    "    plt.title('Learning curves for a %s' % name, fontsize = 18, y = 1.03)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def compare_algorithms(results, names):\n",
    "    fig = pyplot.figure()\n",
    "    fig.suptitle(\"Algorithm Comparison\")\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_title(\"Algorithm Comparison\")\n",
    "    ax.boxplot(results, labels=names)\n",
    "    plot_show()\n",
    "\n",
    "def print_scores(cv_results, predictions):\n",
    "    print('\\nMean %f' % cv_results.mean())\n",
    "    print('STD %f' % cv_results.std())\n",
    "    print('\\nConfusion matrix:')\n",
    "    print(confusion_matrix(y_validation, predictions))\n",
    "    print('\\nAccuracy %f' % accuracy_score(y_validation, predictions))\n",
    "    print('Precision %f' % precision_score(y_validation, predictions, average = 'weighted'))\n",
    "    print('Recall %f' % recall_score(y_validation, predictions, average = 'weighted'))\n",
    "    print('Specificity %f' % get_specificity(y_validation, predictions))\n",
    "    print('\\nClassification report:')\n",
    "    print(classification_report(y_validation, predictions))\n",
    "\n",
    "def plot_roc_curves():\n",
    "    fig = pyplot.figure()\n",
    "    ax = plt.gca()\n",
    "    for name, model, subplot_row in models:\n",
    "        rfc_disp = plot_roc_curve(model, x_validation, \n",
    "                                  y_validation, ax=ax, alpha=0.8)\n",
    "    plt.show()\n",
    "\n",
    "def accuracySignificancy(model, x_train, y_train, cv):\n",
    "    fig = pyplot.figure()\n",
    "    fig.suptitle(\"Estimating accuracy score's statistical significancy\")\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    n_classes = np.unique(y_train).size\n",
    "    score, permutation_scores, pvalue = permutation_test_score(model, x_train, y_train, scoring=\"accuracy\", cv=cv, n_permutations=100)\n",
    "    print(\"Classification score %s (pvalue : %s)\" % (score, pvalue))\n",
    "    # View histogram of permutation scores\n",
    "    ax.hist(permutation_scores, 20, label='Permutation scores',\n",
    "             edgecolor='black')\n",
    "    ylim = plt.ylim()\n",
    "    ax.set_xlabel('Score')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_per_dataset():\n",
    "    results = []\n",
    "    names = []\n",
    "    \n",
    "    for name, model, subplot_row in models:\n",
    "            print(f\"---------------------------\\nRunning classification for: {name}\")\n",
    "            kfold = StratifiedKFold(n_splits=4, random_state=1, shuffle=True)\n",
    "            cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='accuracy')\n",
    "            accuracySignificancy(model, x_train, y_train, kfold)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "\n",
    "            # Make predictions on validation dataset\n",
    "            model.fit(x_train, y_train)\n",
    "            predictions = model.predict(x_validation)\n",
    "            \n",
    "            print_scores(cv_results, predictions)\n",
    "            plot_learning_curve(model,name)\n",
    "\n",
    "    # Compare Algorithms - ROC etc\n",
    "    compare_algorithms(results, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='e3c04f61-72db-4414-87e7-cdbe522f5a20'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_per_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   remote  salary_from  salary_to  .NET  Design  Network  REST API  Embeded  \\\n",
      "0   False      12000.0    15000.0     0       0        0         0        0   \n",
      "1   False      12000.0    18000.0     0       0        0         5        0   \n",
      "2   False      10000.0    16000.0     0       0        0         0        0   \n",
      "5    True      12000.0    18000.0     0       0        0         0        0   \n",
      "6   False       3500.0     5500.0     0       0        0         0        0   \n",
      "\n",
      "   Cloud  Database  ...  CSS  XML  Salesforce  API  Data  Excel  \\\n",
      "0      0         0  ...    0    0           0    0     0      0   \n",
      "1      0         0  ...    0    0           0    0     0      0   \n",
      "2      0         0  ...    0    0           0    0     0      0   \n",
      "5      0         0  ...    0    0           0    0     0      0   \n",
      "6      0         0  ...    0    0           0    0     0      0   \n",
      "\n",
      "   employment_type_b2b  employment_type_mandate_contract  \\\n",
      "0                    1                                 0   \n",
      "1                    0                                 0   \n",
      "2                    1                                 0   \n",
      "5                    1                                 0   \n",
      "6                    0                                 0   \n",
      "\n",
      "   employment_type_permanent  experience_level  \n",
      "0                          0            senior  \n",
      "1                          1               mid  \n",
      "2                          0               mid  \n",
      "5                          0            senior  \n",
      "6                          1            junior  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cl_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl_df = df.copy()\n",
    "for col in [\"salary_to\", \"city\", \"Unnamed: 0\", \"title\", \"company_size\", \"country_code\", \"marker_icon\", \"company_name\",\n",
    "            \"latitude\", \"longitude\", \"salary_currency\", \"published_at\", \"remote_interview\", \"id\",\n",
    "            \"Vert.x\", \"skills\", \"-\"]:\n",
    "                cl_df=cl_df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.91766294 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.22941573 0.         0.         0.         0.22941573 0.22941573\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "cols_for_encoding = [c for c in cl_df.select_dtypes(include=['object', 'boolean']).copy().columns]\n",
    "cl_df = pd.get_dummies(cl_df, columns=cols_for_encoding)\n",
    "cl_df = move_col_to_end(cl_df, \"salary_from\")\n",
    "array = cl_df.values\n",
    "x = array[:, 0:len(cl_df.columns)-1]\n",
    "y = array[:, len(cl_df.columns)-1]\n",
    "x = normalize(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.91766294 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.22941573 0.         0.         0.         0.22941573 0.22941573\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(x,y, test_size=cfg.test_size, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components = 56)\n",
    "# x = pca.fit_transform(x)\n",
    "# print(len(x[0]))\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()  # doctest: +SKIP\n",
    "scaler.fit(x_train)  # doctest: +SKIP\n",
    "x_train = scaler.transform(x_train)  # doctest: +SKIP\n",
    "x_validation = scaler.transform(x_validation)  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['.NET', 'Design', 'Network', 'REST API', 'Embeded', 'Cloud', 'Database',\n",
       "       'Android', 'IT', 'Soft Skills', 'Scrum master', 'Mobile', 'Common',\n",
       "       'JavaScript', 'DevOps', 'Software engineering', 'Testing', 'Automation',\n",
       "       'Shell Scripting', 'Backend', 'Data Science', 'Blockchain', 'C++',\n",
       "       'Client Service', 'Front-end', 'Civil Engineering', 'Developer', 'iOS',\n",
       "       'SQL', 'Python', 'PHP', 'Erlang', 'Scala', 'Git', 'Games', 'Golang',\n",
       "       'Google', 'Java', 'Web', 'Consultant', 'Project Manager', 'Analitics',\n",
       "       'CRM', 'Perl', 'R', 'Ruby', 'Rust', 'SAP', 'CSS', 'XML', 'Salesforce',\n",
       "       'API', 'Data', 'Excel', 'remote_False', 'remote_True',\n",
       "       'experience_level_junior', 'experience_level_mid',\n",
       "       'experience_level_senior', 'employment_type_b2b',\n",
       "       'employment_type_mandate_contract', 'employment_type_permanent',\n",
       "       'salary_from'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuberRegressor MAE: 2750.795273539099 | MSE: 11749567.471620563\n",
      "BayesianRidge MAE: 2813.6405692685244 | MSE: 12025427.63381482\n",
      "Lasso MAE: 2760.9048345522488 | MSE: 11783480.567732621\n",
      "ElasticNet MAE: 2766.7888923442497 | MSE: 11809457.745104097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression, BayesianRidge, Lasso, ElasticNet, Lars, OrthogonalMatchingPursuit, SGDRegressor, ARDRegression\n",
    "from sklearn.linear_model import MultiTaskLasso, MultiTaskLassoCV, HuberRegressor, TheilSenRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def plot_data(axes, title, x_train, y_train, x_test, y_test):\n",
    "    axes.set_title(title)\n",
    "    axes.scatter(x_train[:,0], y_train, color=\"green\"),\n",
    "    axes.plot(x_test, y_test, color=\"red\", linewidth=1)\n",
    "    \n",
    "models = [\n",
    "#     LinearRegression(),\n",
    "    HuberRegressor(alpha=0.00001, epsilon=1.6, max_iter=5000),\n",
    "    BayesianRidge(),\n",
    "#     SGDRegressor(),\n",
    "#     ARDRegression(),\n",
    "#     TheilSenRegressor(),\n",
    "#     MultiTaskLasso(),\n",
    "#     MultiTaskLassoCV(),\n",
    "#     OrthogonalMatchingPursuit(),\n",
    "#     Lars(),\n",
    "#     MLPRegressor(hidden_layer_sizes=(9), solver='lbfgs', tol=1e-6, learning_rate='adaptive', max_iter=3000, n_iter_no_change=100),\n",
    "#     MLPRegressor(hidden_layer_sizes=(9), alpha=1e-8, solver='lbfgs', tol=1e-6, learning_rate='adaptive', max_iter=3000, n_iter_no_change=100),\n",
    "#     MLPRegressor(hidden_layer_sizes=(9), alpha=1, solver='lbfgs', tol=1e-6, learning_rate='adaptive', max_iter=3000, n_iter_no_change=100),\n",
    "#     MLPRegressor(hidden_layer_sizes=(16), solver='sgd', learning_rate='adaptive', max_iter=500, n_iter_no_change=100),\n",
    "#     SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1),\n",
    "#     SVR(kernel='poly', C=100, gamma='scale', degree=3, epsilon=.1, coef0=1),\n",
    "#     SVR(kernel='linear', C=100, gamma='scale'),\n",
    "#     SVR(kernel='rbf'),\n",
    "#     SVR(kernel='poly', degree=60, gamma='scale'),\n",
    "#     SVR(kernel='linear', gamma='scale'),    \n",
    "#     SVR(kernel='sigmoid', gamma='scale'),\n",
    "#     SVR(kernel='precomputed', gamma='auto'),\n",
    "    Lasso(alpha=0.1, max_iter=1000_00, random_state=True),\n",
    "    ElasticNet(alpha=0.01, max_iter=1000_00, random_state=True)]\n",
    "\n",
    "# f, axarr = plt.subplots(len(models), sharex=True, sharey=True,figsize=(12,12))\n",
    "for y, model in enumerate(models):\n",
    "        y_test = model.fit(x_train, y_train).predict(x_validation)\n",
    "#         plot_data(axarr[y], type(model).__name__, x_train, y_train, x_validation, y_test)\n",
    "        print(f\"{type(model).__name__} MAE: {mean_absolute_error(y_validation, y_test, )} | MSE: {mean_squared_error(y_validation, y_test, )}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 9545.556468277246 original: 16800.0\n",
      "predicted: 13296.34761263215 original: 10000.0\n",
      "predicted: 4965.542503553838 original: 3500.0\n",
      "predicted: 12834.83315090558 original: 8000.0\n",
      "predicted: 10465.577019401218 original: 8000.0\n",
      "predicted: 14284.52460886975 original: 15000.0\n",
      "predicted: 14701.578913038866 original: 16000.0\n",
      "predicted: 7419.142491657174 original: 6000.0\n",
      "predicted: 10035.406152744577 original: 8000.0\n",
      "predicted: 7653.1543564451595 original: 3500.0\n",
      "predicted: 16832.254306930114 original: 16000.0\n",
      "predicted: 14883.45129513419 original: 10000.0\n",
      "predicted: 12806.644416044403 original: 14000.0\n",
      "predicted: 10598.493826364362 original: 9000.0\n",
      "predicted: 11777.445095856547 original: 13000.0\n",
      "predicted: 8868.583258044897 original: 8000.0\n",
      "predicted: 11837.423231842562 original: 8000.0\n",
      "predicted: 10588.30311975847 original: 6000.0\n",
      "predicted: 11338.895903513661 original: 14000.0\n",
      "predicted: 10967.58108483097 original: 6000.0\n",
      "predicted: 8234.864446838921 original: 7000.0\n",
      "predicted: 15421.996647769683 original: 11200.0\n",
      "predicted: 15244.735406262274 original: 15000.0\n",
      "predicted: 8914.332173136921 original: 16000.0\n",
      "predicted: 11209.70337289391 original: 11100.0\n",
      "predicted: 8769.988122339828 original: 7000.0\n",
      "predicted: 10581.208339247105 original: 15000.0\n",
      "predicted: 5708.150531893797 original: 8000.0\n",
      "predicted: 16832.254306930114 original: 15470.7\n",
      "predicted: 9579.66003034215 original: 10000.0\n",
      "predicted: 11375.212587563916 original: 12000.0\n",
      "predicted: 10026.013322266619 original: 8000.0\n",
      "predicted: 12134.18997208163 original: 14000.0\n",
      "predicted: 8457.81179939244 original: 10000.0\n",
      "predicted: 11641.151747823866 original: 18000.0\n",
      "predicted: 13779.479457800357 original: 13000.0\n",
      "predicted: 14502.852818147647 original: 12000.0\n",
      "predicted: 12741.885673659643 original: 16800.0\n",
      "predicted: 9264.79212089526 original: 9000.0\n",
      "predicted: 8367.727914674477 original: 5500.0\n",
      "predicted: 13663.704008173336 original: 19000.0\n",
      "predicted: 16476.2519272997 original: 23000.0\n",
      "predicted: 10224.919915189583 original: 16500.0\n",
      "predicted: 12453.902746920206 original: 12000.0\n",
      "predicted: 14116.780390637601 original: 8000.0\n",
      "predicted: 11613.080703514843 original: 14000.0\n",
      "predicted: 13077.710110164355 original: 18000.0\n",
      "predicted: 13871.424068795211 original: 12500.0\n",
      "predicted: 3613.424921986347 original: 3500.0\n",
      "predicted: 11930.138657005667 original: 10000.0\n",
      "predicted: 8541.410032433338 original: 11000.0\n",
      "predicted: 10754.452670531453 original: 11000.0\n",
      "predicted: 10450.478010464047 original: 12000.0\n",
      "predicted: 13591.02024247043 original: 12000.0\n",
      "predicted: 14259.271120428642 original: 15500.0\n",
      "predicted: 12316.14722430287 original: 12000.0\n",
      "predicted: 13720.426853497564 original: 10000.0\n",
      "predicted: 16993.290121930866 original: 14000.0\n",
      "predicted: 12268.095659205 original: 15120.0\n",
      "predicted: 9645.362154195378 original: 14000.0\n",
      "predicted: 12579.948569027529 original: 16800.0\n",
      "predicted: 8602.824422794863 original: 6000.0\n",
      "predicted: 9319.109825142903 original: 7000.0\n",
      "predicted: 11574.241787833116 original: 10000.0\n",
      "predicted: 13990.211551853497 original: 14000.0\n",
      "predicted: 14459.33728030089 original: 12000.0\n",
      "predicted: 15902.16525247783 original: 10000.0\n",
      "predicted: 9603.942725878023 original: 6500.0\n",
      "predicted: 11633.862827119527 original: 5000.0\n",
      "predicted: 9482.991479016595 original: 6000.0\n",
      "predicted: 7419.142491657174 original: 6000.0\n",
      "predicted: 9185.119388232164 original: 6000.0\n",
      "predicted: 8998.243298068644 original: 8000.0\n",
      "predicted: 6580.168560231944 original: 7000.0\n",
      "predicted: 14228.21806864301 original: 8000.0\n",
      "predicted: 9188.721137928364 original: 12000.0\n",
      "predicted: 12503.37099790514 original: 14000.0\n",
      "predicted: 10460.789982665923 original: 8000.0\n",
      "predicted: 7390.87928739149 original: 9000.0\n",
      "predicted: 8247.841089459576 original: 5000.0\n",
      "predicted: 14746.40431104416 original: 15000.0\n",
      "predicted: 12503.37099790514 original: 8000.0\n",
      "predicted: 13214.484898252142 original: 12000.0\n",
      "predicted: 11992.610483595148 original: 16800.0\n",
      "predicted: 12870.824352907897 original: 18000.0\n",
      "predicted: 10491.903446728773 original: 19000.0\n",
      "predicted: 11398.390656043353 original: 14500.0\n",
      "predicted: 12377.061078587112 original: 9000.0\n",
      "predicted: 14781.311644371543 original: 12000.0\n",
      "predicted: 7459.137793237565 original: 8000.0\n",
      "predicted: 4375.963018552763 original: 4000.0\n",
      "predicted: 11126.674058020002 original: 10000.0\n",
      "predicted: 10580.078341920398 original: 15000.0\n",
      "predicted: 9738.33597633448 original: 8000.0\n",
      "predicted: 13718.203255407865 original: 14000.0\n",
      "predicted: 14777.562833127515 original: 17000.0\n",
      "predicted: 8159.035947399154 original: 7000.0\n",
      "predicted: 15640.761206407511 original: 16800.0\n",
      "predicted: 10539.807594988622 original: 9000.0\n",
      "predicted: 11653.888779365627 original: 8000.0\n",
      "predicted: 11980.519820149213 original: 12000.0\n",
      "predicted: 10475.315736215833 original: 12500.0\n",
      "predicted: 14063.387198884342 original: 12000.0\n",
      "predicted: 11061.20655211595 original: 13000.0\n",
      "predicted: 8611.155240145657 original: 14000.0\n",
      "predicted: 9711.171193055176 original: 10000.0\n",
      "predicted: 8625.345731979143 original: 6000.0\n",
      "predicted: 9277.424679141921 original: 11000.0\n",
      "predicted: 12944.731427331362 original: 13000.0\n",
      "predicted: 8414.626715620056 original: 10000.0\n",
      "predicted: 10366.073915473098 original: 8000.0\n",
      "predicted: 9145.663778284867 original: 10000.0\n",
      "predicted: 11634.593160127846 original: 15000.0\n",
      "predicted: 8902.792671779382 original: 7500.0\n",
      "predicted: 3889.000975959514 original: 4000.0\n",
      "predicted: 8902.792671779382 original: 11000.0\n",
      "predicted: 11581.725875934077 original: 12000.0\n",
      "predicted: 14259.271120428642 original: 15000.0\n",
      "predicted: 12210.221835374317 original: 7500.0\n",
      "predicted: 16484.747788490196 original: 12000.0\n",
      "predicted: 10460.789982665923 original: 12000.0\n",
      "predicted: 14917.186428783443 original: 10000.0\n",
      "predicted: 12216.77465839531 original: 14200.0\n",
      "predicted: 11272.174209422481 original: 9000.0\n",
      "predicted: 9357.206365150972 original: 9000.0\n",
      "predicted: 10438.09229373454 original: 9000.0\n",
      "predicted: 11077.607298223236 original: 17000.0\n",
      "predicted: 9637.598622948584 original: 17856.0\n",
      "predicted: 11717.186673281056 original: 14000.0\n",
      "predicted: 11077.607298223236 original: 13000.0\n",
      "predicted: 12022.01113584332 original: 19000.0\n",
      "predicted: 14276.358649287351 original: 20000.0\n",
      "predicted: 14213.102877205705 original: 17000.0\n",
      "predicted: 14987.119627201502 original: 8500.0\n",
      "predicted: 9105.864119455719 original: 5000.0\n",
      "predicted: 14517.277776277064 original: 20000.0\n",
      "predicted: 16273.880472396158 original: 15000.0\n",
      "predicted: 12541.81020550667 original: 14000.0\n",
      "predicted: 11229.926431137364 original: 6700.0\n",
      "predicted: 11032.170223014364 original: 13000.0\n",
      "predicted: 13071.067764683494 original: 10000.0\n",
      "predicted: 14550.117424495811 original: 13000.0\n",
      "predicted: 12037.830045006636 original: 11000.0\n",
      "predicted: 11582.68165737851 original: 8000.0\n",
      "predicted: 15227.301041716839 original: 13000.0\n",
      "predicted: 10921.655091111998 original: 6750.0\n",
      "predicted: 8684.532444770892 original: 12000.0\n",
      "predicted: 10575.139533142541 original: 15000.0\n",
      "predicted: 9827.518119555674 original: 10000.0\n",
      "predicted: 8795.603342593322 original: 10000.0\n",
      "predicted: 11604.134796254108 original: 8000.0\n",
      "predicted: 17075.125413435595 original: 14000.0\n",
      "predicted: 13637.839635812157 original: 14700.0\n",
      "predicted: 11856.059667315674 original: 16000.0\n",
      "predicted: 17879.270232485047 original: 16000.0\n",
      "predicted: 14076.089958111312 original: 12000.0\n",
      "predicted: 15146.743858951026 original: 20000.0\n",
      "predicted: 8403.497612068884 original: 14000.0\n",
      "predicted: 6545.986228802692 original: 5000.0\n",
      "predicted: 12749.574542914905 original: 7000.0\n",
      "predicted: 8869.591289011372 original: 5000.0\n",
      "predicted: 10389.378479473033 original: 8000.0\n",
      "predicted: 15766.28590883442 original: 13000.0\n",
      "predicted: 10554.632001819167 original: 12000.0\n",
      "predicted: 13114.0592520913 original: 18900.0\n",
      "predicted: 10817.860549926052 original: 14000.0\n",
      "predicted: 9546.385197960042 original: 10000.0\n",
      "predicted: 6823.541584776707 original: 7000.0\n",
      "predicted: 7393.484759478195 original: 6000.0\n",
      "predicted: 9130.627084328655 original: 5000.0\n",
      "predicted: 10588.30311975847 original: 6000.0\n",
      "predicted: 11814.58265729332 original: 9000.0\n",
      "predicted: 9381.741734179532 original: 8000.0\n",
      "predicted: 10687.857312267442 original: 7000.0\n",
      "predicted: 7929.359657552031 original: 4000.0\n",
      "predicted: 10556.332424855438 original: 8000.0\n",
      "predicted: 14216.177852753583 original: 16000.0\n",
      "predicted: 13117.663817482142 original: 14000.0\n",
      "predicted: 12134.18997208163 original: 12000.0\n",
      "predicted: 10973.281095069355 original: 9000.0\n",
      "predicted: 11790.3296927342 original: 18000.0\n",
      "predicted: 10810.568755258519 original: 9500.0\n",
      "predicted: 14183.77954279236 original: 15000.0\n",
      "predicted: 10377.317343854966 original: 8000.0\n",
      "predicted: 9327.29339413942 original: 10000.0\n",
      "predicted: 9120.63795379058 original: 9000.0\n",
      "predicted: 11493.931309618052 original: 6000.0\n",
      "predicted: 6586.233382372384 original: 7000.0\n",
      "predicted: 10626.499518355178 original: 18000.0\n",
      "predicted: 10141.633757555084 original: 12000.0\n",
      "predicted: 7758.5052730679945 original: 8000.0\n",
      "predicted: 7621.4363112274195 original: 6000.0\n",
      "predicted: 14259.271120428642 original: 11000.0\n",
      "predicted: 12665.266298704084 original: 20000.0\n",
      "predicted: 11867.505696795153 original: 10500.0\n",
      "predicted: 7343.786964296155 original: 3500.0\n",
      "predicted: 8952.536564421647 original: 7000.0\n",
      "predicted: 13147.627897997814 original: 14000.0\n",
      "predicted: 10147.208189011477 original: 7500.0\n",
      "predicted: 4908.557589315277 original: 3000.0\n",
      "predicted: 11919.688706503635 original: 18000.0\n",
      "predicted: 7578.217386911127 original: 6320.886\n",
      "predicted: 15228.307229738526 original: 11100.0\n",
      "predicted: 11306.870897040599 original: 8000.0\n",
      "predicted: 9724.268094812885 original: 8500.0\n",
      "predicted: 12674.988852548415 original: 14000.0\n",
      "predicted: 12870.824352907897 original: 14000.0\n",
      "predicted: 15368.654569228409 original: 9000.0\n",
      "predicted: 11424.335443549122 original: 6000.0\n",
      "predicted: 11875.735853230775 original: 7000.0\n",
      "predicted: 8411.693167862166 original: 4000.0\n",
      "predicted: 8774.699337533022 original: 18000.0\n",
      "predicted: 16424.067041276434 original: 20000.0\n",
      "predicted: 8180.676665346215 original: 8000.0\n",
      "predicted: 10226.706807618273 original: 4300.0\n",
      "predicted: 12351.835727580064 original: 15000.0\n",
      "predicted: 15146.743858951026 original: 16000.0\n",
      "predicted: 6985.152808236535 original: 11000.0\n",
      "predicted: 9569.418162887245 original: 14000.0\n",
      "predicted: 10147.208189011477 original: 11000.0\n",
      "predicted: 14338.564946997012 original: 20000.0\n",
      "predicted: 10967.58108483097 original: 12000.0\n",
      "predicted: 11822.585847210046 original: 6500.0\n",
      "predicted: 11966.159020058287 original: 13000.0\n",
      "predicted: 11197.179015197351 original: 15000.0\n",
      "predicted: 10215.17175871452 original: 7000.0\n",
      "predicted: 11760.000193282453 original: 14000.0\n",
      "predicted: 13542.965635012553 original: 14000.0\n",
      "predicted: 13608.945835442972 original: 18900.0\n",
      "predicted: 10188.544192314632 original: 12000.0\n",
      "predicted: 8176.901021238657 original: 7000.0\n",
      "predicted: 9445.992770140947 original: 10000.0\n",
      "predicted: 7882.3448077770145 original: 10000.0\n",
      "predicted: 13057.545051195355 original: 14000.0\n",
      "predicted: 10849.86984747585 original: 16800.0\n",
      "predicted: 14452.824408415192 original: 13000.0\n",
      "predicted: 13601.815226061259 original: 12000.0\n",
      "predicted: 16463.0732811066 original: 16000.0\n",
      "predicted: 13201.205792946876 original: 7000.0\n",
      "predicted: 11262.319792149023 original: 22000.0\n",
      "predicted: 8776.688023348086 original: 7000.0\n",
      "predicted: 10154.709489992447 original: 8000.0\n",
      "predicted: 12856.000324859317 original: 17000.0\n",
      "predicted: 12411.075574728482 original: 12000.0\n",
      "predicted: 17248.68908831243 original: 19200.0\n",
      "predicted: 8339.9025124724 original: 10500.0\n"
     ]
    }
   ],
   "source": [
    "for i, y in enumerate(y_validation):\n",
    "    print(f\"predicted: {y_test[i]} original: {y_validation[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array 10500.0 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a612abf49858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m }\n\u001b[1;32m     24\u001b[0m \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameter (CV score=%0.3f):\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 152\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array 10500.0 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "\n",
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pca = PCA()\n",
    "bayesian = BayesianRidge() #(max_iter=10000, tol=0.1)\n",
    "pipe = Pipeline(steps=[('pca', pca), ('bayesian', bayesian)])\n",
    "param_grid = {\n",
    "    'pca__n_components': [5, 15, 30, 45, 64]\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "search.fit(x, y)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "# Plot the PCA spectrum\n",
    "pca.fit(x)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\n",
    "ax0.plot(np.arange(1, pca.n_components_ + 1),\n",
    "         pca.explained_variance_ratio_, '+', linewidth=2)\n",
    "ax0.set_ylabel('PCA explained variance ratio')\n",
    "\n",
    "ax0.axvline(search.best_estimator_.named_steps['pca'].n_components,\n",
    "            linestyle=':', label='n_components chosen')\n",
    "ax0.legend(prop=dict(size=12))\n",
    "\n",
    "# For each number of components, find the best classifier results\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "components_col = 'param_pca__n_components'\n",
    "best_clfs = results.groupby(components_col).apply(\n",
    "    lambda g: g.nlargest(1, 'mean_test_score'))\n",
    "\n",
    "best_clfs.plot(x=components_col, y='mean_test_score', yerr='std_test_score',\n",
    "               legend=False, ax=ax1)\n",
    "ax1.set_xlabel('n_components')\n",
    "\n",
    "plt.xlim(-1, 70)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
